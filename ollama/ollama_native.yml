# =============================================================================
# Harbor Native Service Contract: Ollama
# =============================================================================
#
# This file defines the native execution configuration for the Ollama service
# in Harbor. When Harbor is configured to run Olloma natively (instead of in
# a container), this contract specifies how to start the service and integrate
# it with Harbor's hybrid orchestration system.
#
# NATIVE SCRIPT INTEGRATION:
# This YAML file works in conjunction with 'ollama_native.sh', which serves
# as the entrypoint script. Harbor reads this configuration, then calls the
# native script with the specified executable and arguments using a Docker-style
# pattern.
#
# EXECUTION FLOW:
# 1. Harbor reads this YAML file to understand the native service configuration
# 2. Harbor calls: ollama_native.sh "ollama" "serve"
# 3. The native script executes: exec ollama serve
# 4. The process runs natively on the host, with logs redirected to Harbor's log directory
#
# REQUIREMENTS:
# - The 'ollama' binary must be installed and available in the system's PATH
# - The native script (ollama_native.sh) must be executable
# - Harbor manages the process lifecycle via PID files and log redirection
#
# TROUBLESHOOTING:
# - Logs are written to: $HARBOR_HOME/app/backend/data/logs/harbor-ollama-native.log
# - PID file location: $HARBOR_HOME/app/backend/data/pids/ollama.pid
# - Check binary availability: command -v ollama
# - Verify script permissions: ls -la ollama_native.sh
#
# =============================================================================
# ========================================================================
# == Harbor v22.0: Unified Native Contract for 'ollama'
# ========================================================================
#
# This file serves a dual purpose and is the heart of Harbor's hybrid runtime:
#
# 1. A Docker Compose Override File: This file defines a lightweight "proxy"
#    service. When 'ollama' is run in NATIVE mode, Harbor's composer
#    will EXCLUDE the standard 'compose.ollama.yml' (the container definition)
#    and INCLUDE this file instead. This effectively REPLACES the real service
#    with this proxy in the eyes of Docker Compose.
#
# 2. A Native Metadata Contract: The 'x-harbor-native' block contains all
#    the information Harbor needs to start, stop, manage, and configure the
#    actual native 'ollama' process running on the host machine. Docker
#    Compose safely ignores fields starting with 'x-'.
#
services:
  # The top-level service key MUST match the Harbor service handle ('ollama').
  ollama:
    # --------------------------------------------------------------------
    # -- Section 1: Proxy Container Definition
    #    This section defines the lightweight container that will represent
    #    the native 'ollama' service within the Docker network.
    # --------------------------------------------------------------------

    # The Docker image to use for the proxy container. A minimal image with
    # networking tools is ideal. 'alpine/socat' is a common, robust choice.
    image: alpine/socat:latest
    container_name: ${HARBOR_CONTAINER_PREFIX:-harbor}.ollama

    # The command for the proxy container. This uses 'socat' to create a TCP
    # listener on the specified port inside the container and forward all
    # traffic to the native service running on the host. 'host.docker.internal'
    # is the special DNS name that Docker provides for containers to connect
    # back to the host machine.
    command: tcp-listen:11434,fork,reuseaddr tcp-connect:host.docker.internal:11434

    # The healthcheck for the proxy container. This is the KEY to making hybrid
    # dependencies work. This test does NOT check the proxy itself; it checks
    # the readiness of the ACTUAL NATIVE SERVICE on the host. This ensures that
    # any container with `depends_on: ollama` will correctly wait until the
    # native Ollama daemon is fully initialized and ready to accept connections.
    healthcheck:
      test: ["CMD-SHELL", "nc -z host.docker.internal 11434 || exit 1"]
      interval: 2s
      timeout: 5s
      retries: 30
      start_period: 5s

    # Ensures the proxy can be discovered by other services in the stack.
    networks:
      - harbor-network

    # --------------------------------------------------------------------
    # -- Section 2: Native Process Metadata (The Harbor Contract)
    #    This custom block is ignored by Docker Compose but is parsed by
    #    Harbor's scripts to manage the native process lifecycle.
    # --------------------------------------------------------------------
    x-harbor-native:
      # ================================================================
      # == Native Execution Configuration (Docker-Style Pattern)
      # ================================================================
      #
      # Harbor uses a Docker-style ENTRYPOINT + CMD pattern for native services:
      # - 'executable': Like Docker's ENTRYPOINT - the binary to execute
      # - 'daemon_args': Like Docker's CMD - the arguments for daemon startup
      #
      # This design allows:
      # 1. Daemon startup: executable + daemon_args = "ollama serve"
      # 2. User commands: executable + user_args = "ollama list", "ollama pull model"
      # 3. Different executable names: executable can be "/usr/local/bin/custom-ollama"
      # 4. Flexible arguments: daemon_args can be ["serve", "--debug", "--verbose"]
      #
      # Harbor calls: native_script.sh "ollama" "serve"
      # Native script executes: exec "$@"  (i.e., exec ollama serve)

      # The executable binary name or path for this service.
      # Used for both daemon startup and user commands (e.g., `harbor run ollama list`).
      # Can be just the binary name (if in PATH) or a full path.
      # Examples: "ollama", "/usr/local/bin/ollama", "/opt/custom/ollama-v2"
      executable: "ollama"

      # The arguments to pass to the executable when starting the daemon.
      # This replaces the old 'daemon_command' field and supports complex arguments.
      # Examples: ["serve"], ["serve", "--debug"], ["start", "--port", "11434"]
      daemon_args: ["serve"]

      # The TCP port that the native daemon process will listen on. This is used
      # by the proxy's command and healthcheck.
      port: 11434

      # A boolean (true/false) flag that informs Harbor's "auto" execution preference.
      # If true, `auto` mode will prefer to run this service natively on platforms
      # where Docker has poor GPU support (i.e., Apple Silicon) to ensure max performance.
      requires_gpu_passthrough: true

      # A list of environment variables from Harbor's main .env file that should be
      # exported into the environment of the native process before it is started.
      # This allows for consistent configuration of both native and container services.
      env_vars:
        - "OLLAMA_DEBUG"
        - "OLLAMA_KEEP_ALIVE"

      # A map of environment variables that Harbor will inject into OTHER, DEPENDENT
      # containers during `harbor up`. This allows containerized apps (like a web UI)
      # to correctly configure themselves to find and connect to the native service.
      # Example: This sets HARBOR_OLLAMA_INTERNAL_URL for the 'webui' container.
      env_overrides:
        HARBOR_OLLAMA_INTERNAL_URL: "http://host.docker.internal:11434"