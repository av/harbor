### [openedai-speech](https://github.com/matatonic/openedai-speech)

> Handle: `tts`
> URL: [http://localhost:33861/](http://localhost:33861/)

An OpenAI API compatible text to speech server.

#### Starting

```bash
# [Optional] Pull the tts images
# ahead of starting the service
harbor pull tts

# Sping up Harbor with the TTS instance
harbor up tts
```

Upon the first start, service will initialise its cache and download the necessary models. You can find both in the `tts` folder in the Harbor workspace.

#### Configuration

`openedai-speech` runs two types of models out of the box - `tts-1` (via [piper tts](https://github.com/rhasspy/piper), very fast, runs on cpu) and `tts-1-hd` (via [xtts_v2](https://github.com/idiap/coqui-ai-TTS)  with voice cloning, fast but requires around ~4Gb of VRAM).

##### tts-1

You can map your [Piper voices](https://rhasspy.github.io/piper-samples/) via the [./tts/config/voice_to_speaker.yaml](./tts/config/voice_to_speaker.yaml) file.

Download more voices from the official Piper repo [here](https://github.com/rhasspy/piper/blob/master/VOICES.md).

##### tts-1-hd

[xtts_v2](https://github.com/idiap/coqui-ai-TTS) provides you with a voice cloning feature. It can deliver very pleasant and natural sounding voices with appropriate samples. See the [official repo guide](https://github.com/matatonic/openedai-speech?tab=readme-ov-file#coqui-xtts-v2) on how to set up the voice cloning.

You can find more detailed documentation about `openedai-speech` configuration in the [official repository](https://github.com/matatonic/openedai-speech?tab=readme-ov-file#openedai-speech).
