### [AI Runner](https://github.com/Capsize-Games/airunner)

> Handle: `airunner`<br/>
> URL: [http://localhost:34461](http://localhost:34461)

Run local AI models for text, images, text-to-speech, and speech-to-text.

### Starting

```bash
# [Optional] Pre-pull the image
harbor pull airunner

# Start the service
# ⚠️ First start will take a long time,
# as it installs very large dependencies (CUDA, PyTorch)
harbor up airunner
```

See [troubleshooting guide](./1.-Harbor-User-Guide.md#troubleshooting) if you encounter any issues.

- Base image for the service is relatively slim (~1.6Gb), but it has dynamic initialization on the first start that will download and install a lot of dependencies (CUDA, PyTorch, etc.)
  - This will take a long time and quite a bit of disk space
    - _TIP_: use [`harbor size`](./3.-Harbor-CLI-Reference.md#harbor-size) to check the size of folders managed by Harbor


#### Usage

You'll perform most actions in the LocalAI WebUI, run [`harbor open`](./3.-Harbor-CLI-Reference.md#harbor-open-service) to access it.

- After initial start, go to the Models Gallery and download a model of your choice.
- After downloading, model will appear in LocalAI home page, where you can start a chat with it

#### Configuration

See official [Environment Variables guide](https://localai.io/advanced/#environment-variables) for reference.

Following options can be set via [`harbor config`](./3.-Harbor-CLI-Reference#harbor-config):

```bash
# The port on the host where LocalAI endpoint will be available
LOCALAI_HOST_PORT              34451

# Docker image to use for the LocalAI service
LOCALAI_IMAGE                  localai/localai

# Docker tag when no Nvidia/ROCm support is detected
LOCALAI_CPU_VERSION            latest-cpu

# Docker tag when Nvidia support is detected
LOCALAI_NVIDIA_VERSION         latest-gpu-nvidia-cuda-12

# Docker tag when ROCm support is detected
LOCALAI_ROCM_VERSION           latest-gpu-hipblas

# Location on the host to store files for the LocalAI service
# Should be either relative to $(harbor home) or absolute
LOCALAI_WORKSPACE              ./localai/data
```

See [environment configuration guide](./1.-Harbor-User-Guide#environment-variables) to set arbitrary environment variables for the service.
